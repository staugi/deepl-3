{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f46aad-410c-445e-a786-cdc9b429498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_dir = \"dataset_coco/annotations\"\n",
    "dataset = \"instances_train2017.json\"\n",
    "dataset_path = f\"{dataset_dir}/{dataset}\"\n",
    "INPUT_JSON = dataset_path\n",
    "OUTPUT_JSON = f\"{dataset_dir}/instances_train2017_filtered_balanced.json\"\n",
    "CLASSES_TO_KEEP = [\"chair\", \"motorcycle\"]\n",
    "N = 2000  # Total number of images to keep (must be even)\n",
    "\n",
    "# --- Load COCO annotations ---\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Get category IDs for the classes to keep ---\n",
    "cat_name_to_id = {cat[\"name\"]: cat[\"id\"] for cat in data[\"categories\"]}\n",
    "keep_ids = {name: cat_name_to_id[name] for name in CLASSES_TO_KEEP}\n",
    "\n",
    "# --- Group annotations by image ---\n",
    "anns_by_image = defaultdict(list)\n",
    "for ann in data[\"annotations\"]:\n",
    "    if ann[\"category_id\"] in keep_ids.values():\n",
    "        anns_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "# --- Map image_id to which classes it contains ---\n",
    "image_classes = defaultdict(set)\n",
    "for image_id, anns in anns_by_image.items():\n",
    "    for ann in anns:\n",
    "        for class_name, class_id in keep_ids.items():\n",
    "            if ann[\"category_id\"] == class_id:\n",
    "                image_classes[image_id].add(class_name)\n",
    "\n",
    "# --- Separate images by dominant class ---\n",
    "class_to_images = {cls: [] for cls in CLASSES_TO_KEEP}\n",
    "for image_id, classes in image_classes.items():\n",
    "    for cls in CLASSES_TO_KEEP:\n",
    "        if cls in classes and len(classes) == 1:  # Use only single-class images for strict balance\n",
    "            class_to_images[cls].append(image_id)\n",
    "\n",
    "# --- Sample N/2 images per class ---\n",
    "num_per_class = N // 2\n",
    "selected_img_ids = set()\n",
    "for cls in CLASSES_TO_KEEP:\n",
    "    imgs = class_to_images[cls]\n",
    "    if len(imgs) < num_per_class:\n",
    "        raise ValueError(f\"Not enough images for class '{cls}' (needed {num_per_class}, found {len(imgs)})\")\n",
    "    selected_img_ids.update(random.sample(imgs, num_per_class))\n",
    "\n",
    "# --- Collect new annotations and images ---\n",
    "new_annotations = []\n",
    "new_images = []\n",
    "image_id_set = set(selected_img_ids)\n",
    "\n",
    "for img in data[\"images\"]:\n",
    "    if img[\"id\"] in image_id_set:\n",
    "        new_images.append(img)\n",
    "        new_annotations.extend(anns_by_image[img[\"id\"]])\n",
    "\n",
    "# --- Build filtered data dict ---\n",
    "filtered_data = {\n",
    "    \"info\": data.get(\"info\", {}),\n",
    "    \"licenses\": data.get(\"licenses\", []),\n",
    "    \"images\": new_images,\n",
    "    \"annotations\": new_annotations,\n",
    "    \"categories\": [cat for cat in data[\"categories\"] if cat[\"name\"] in CLASSES_TO_KEEP]\n",
    "}\n",
    "\n",
    "# --- Save to output file ---\n",
    "with open(OUTPUT_JSON, \"w\") as f:\n",
    "    json.dump(filtered_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b37952-784e-4954-96e7-35aa4d887083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_dir = \"dataset_coco/annotations\"\n",
    "dataset = \"instances_val2017.json\"\n",
    "dataset_path = f\"{dataset_dir}/{dataset}\"\n",
    "INPUT_JSON = dataset_path\n",
    "OUTPUT_JSON = f\"{dataset_dir}/instances_val2017_filtered_balanced.json\"\n",
    "CLASSES_TO_KEEP = [\"chair\", \"motorcycle\"]\n",
    "N = 200  # Total number of images to keep (must be even)\n",
    "\n",
    "# --- Load COCO annotations ---\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Get category IDs for the classes to keep ---\n",
    "cat_name_to_id = {cat[\"name\"]: cat[\"id\"] for cat in data[\"categories\"]}\n",
    "keep_ids = {name: cat_name_to_id[name] for name in CLASSES_TO_KEEP}\n",
    "\n",
    "# --- Group annotations by image ---\n",
    "anns_by_image = defaultdict(list)\n",
    "for ann in data[\"annotations\"]:\n",
    "    if ann[\"category_id\"] in keep_ids.values():\n",
    "        anns_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "# --- Map image_id to which classes it contains ---\n",
    "image_classes = defaultdict(set)\n",
    "for image_id, anns in anns_by_image.items():\n",
    "    for ann in anns:\n",
    "        for class_name, class_id in keep_ids.items():\n",
    "            if ann[\"category_id\"] == class_id:\n",
    "                image_classes[image_id].add(class_name)\n",
    "\n",
    "# --- Separate images by dominant class ---\n",
    "class_to_images = {cls: [] for cls in CLASSES_TO_KEEP}\n",
    "for image_id, classes in image_classes.items():\n",
    "    for cls in CLASSES_TO_KEEP:\n",
    "        if cls in classes and len(classes) == 1:  # Use only single-class images for strict balance\n",
    "            class_to_images[cls].append(image_id)\n",
    "\n",
    "# --- Sample N/2 images per class ---\n",
    "num_per_class = N // 2\n",
    "selected_img_ids = set()\n",
    "for cls in CLASSES_TO_KEEP:\n",
    "    imgs = class_to_images[cls]\n",
    "    if len(imgs) < num_per_class:\n",
    "        raise ValueError(f\"Not enough images for class '{cls}' (needed {num_per_class}, found {len(imgs)})\")\n",
    "    selected_img_ids.update(random.sample(imgs, num_per_class))\n",
    "\n",
    "# --- Collect new annotations and images ---\n",
    "new_annotations = []\n",
    "new_images = []\n",
    "image_id_set = set(selected_img_ids)\n",
    "\n",
    "for img in data[\"images\"]:\n",
    "    if img[\"id\"] in image_id_set:\n",
    "        new_images.append(img)\n",
    "        new_annotations.extend(anns_by_image[img[\"id\"]])\n",
    "\n",
    "# --- Build filtered data dict ---\n",
    "filtered_data = {\n",
    "    \"info\": data.get(\"info\", {}),\n",
    "    \"licenses\": data.get(\"licenses\", []),\n",
    "    \"images\": new_images,\n",
    "    \"annotations\": new_annotations,\n",
    "    \"categories\": [cat for cat in data[\"categories\"] if cat[\"name\"] in CLASSES_TO_KEEP]\n",
    "}\n",
    "\n",
    "# --- Save to output file ---\n",
    "with open(OUTPUT_JSON, \"w\") as f:\n",
    "    json.dump(filtered_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb172b7a-e54a-454d-9de0-26f3e7646dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
